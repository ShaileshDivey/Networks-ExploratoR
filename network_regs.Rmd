---
title: "FeatureSelection_IndustryFundamentals"
author: "Shailesh Divey"
date: "02/10/2021"
output: html_notebook
---

```{r}
# Clean R environment
rm(list=ls())
# Set seed for reproducibility
set.seed(123)
```


```{r}
library(tidyverse)
#library(dplyr)
library(lubridate)
library(data.table)
library(foreign)
library(readstata13)
library(xts)
library(DataCombine)
library(caret)
library(leaps)
library(MASS)
library(readxl)
library(xlsx)
library(ggplot2)
library(imputeTS)
```


```{r}
getwd()
# list.files()
# list.files("~")
```


```{r}
setwd("C:\\TestData\\AY20202021\\fin_data_20_21")
```


```{r}
# df.dat = read.csv("df_reg_index_new.csv", encoding="UFT-8", check.names=FALSE)
df.dat = read.csv("df_reg_index_new_Ass.csv", encoding="UFT-8", check.names=FALSE)
head(df.dat)
```

```{r}
# df.dat <- transform(df.dat, Year = as.Date(as.character(Year), "%Y"))
# df.dat$Year <- as.Date(df.dat$Year, format='%Y')
df.dat$Year <- as.Date(ISOdate(df.dat$Year, 12, 31))  # end of year
```


```{r}
str(df.dat)
```


```{r}
df.dat2 <- df.dat
head(df.dat2)
# dim(df.dat2)
# summary(df.dat2)
```


```{r}
rownames(df.dat2) <- df.dat2$Year
head(df.dat2)
```

```{r}
drops <- c("Year")
df.dat2 <- df.dat2[ , !(names(df.dat2) %in% drops)]
head(df.dat2)
```

```{r}
colSums(df.dat2 == 0)
```

## Drop rows and columns with any/all zeros 

```{r}
dim(df.dat2)
df.dat2 <- df.dat2[, colSums(df.dat2 != 0) > 0]
# df.dat2 <- df.dat2[apply(df.dat2, 1, function(row) all(row ==0 )), ]  # Remove zero-rows
# df.dat2 <- df.dat2 [rowSums(df.dat2) > 0, ]
# df.dat2 <- df.dat2[is.finite(rowSums(log(df.dat2[-1]))),]
# all numeric variables must be non-zero
# df.dat2 <- filter_if(df.dat2, is.numeric, all_vars((.) != 0))
dim(df.dat2)
```

## Compute and Plot Correlations
### http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

```{r}
res <- cor(df.dat2[,2:68], use="complete.obs")
round(res, 2)
```


```{r}
library(Hmisc)

# ++++++++++++++++++++++++++++
# flattenCorrMatrix
# ++++++++++++++++++++++++++++
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

```


```{r}
# Extract the correlation coefficients and p-values
res2<-rcorr(as.matrix(df.dat2[,2:68]))
flattenCorrMatrix(res2$r, res2$P)
```


```{r}
# library(corrplot)
# corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)
```


```{r}
# # Insignificant correlation are crossed
# corrplot(res2$r, type="upper", order="hclust", p.mat = res2$P, 
#          sig.level = 0.01, insig = "blank")
# 
# # Insignificant correlations are leaved blank
# corrplot(res2$r, type="upper", order="hclust", p.mat = res2$P, 
#          sig.level = 0.01, insig = "blank")

```


## Stepwise Regression
### http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/

```{r}
# #Does not work(????)

# Fit the full model 
full.model <- lm(Clustering ~., data = df.dat2)
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both", trace = FALSE)
summary(step.model)
```


```{r}
# #Does not work(????)

models <- regsubsets(Clustering ~., data = df.dat2, nvmax = 5, method = "seqrep")
summary(models)
```


```{r}
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "cv", number = 10)
# Train the model
step.model <- train(Clustering ~., data = df.dat2,
                    method = "leapBackward", 
                    tuneGrid = data.frame(nvmax = 1:5),
                    trControl = train.control
                    )

step.model$results
```


```{r}
step.model$bestTune
```


```{r}
summary(step.model$finalModel)
```

```{r}
coef(step.model$finalModel, 2)
```

## Bayesian Model Averaging (bayesian averaging of classical estimates for feature selection)

```{r}
library(dplyr)

# df.dat2 %>% 
#   mutate_at(vars(-("Clustering")),lag)

df.dat2 %>% 
  mutate_at(vars(-("Assortativity")),lag)
```


```{r}
library(BMS)
att = bms(df.dat2, mprior = "uniform", g = "UIP", user.int = F)
coef(att)
```


```{r}
coef(att, std.coefs = T, order.by.pip = F, include.constant = T)
```


```{r}
summary(att)
```


```{r}
topmodels.bma(att)[, 1:3]
```

```{r}
# beta.draws.bma(att)
image(att)
```


```{r}
sum(coef(att)[, 1])
```


```{r}
plotModelsize(att)
```

```{r}
write.csv(topmodels.bma(att)[, 1:3], file = "bms_top3_yesLag_re_ass.csv")
```


```{r}
# library(tidyquant)
# library(timetk)
```







